{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9bb5a8-aa9c-4a20-8aa1-3272001e65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fffd54d-da45-4d91-9e38-950dc9af63c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m'''步骤一，导入本项目所需要的模块和包，从 Keras 中导入 Cifar-10 数据集，将训练集的特征值和标签值分别存储在\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mx_train 和 y_train 中，将测试集的特征值和标签值分别存储在 x_test 和 y_test 中。将特征值 x_train 和 x_test \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m的数据类型转换为 tf.float32，并进行标准化处理，使其取值范围为 0～1；将标签值 y_train 和 y_test的数据类型转换为 tf.int32。'''\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 导入所需要的模块与包\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "'''步骤一，导入本项目所需要的模块和包，从 Keras 中导入 Cifar-10 数据集，将训练集的特征值和标签值分别存储在\n",
    "x_train 和 y_train 中，将测试集的特征值和标签值分别存储在 x_test 和 y_test 中。将特征值 x_train 和 x_test \n",
    "的数据类型转换为 tf.float32，并进行标准化处理，使其取值范围为 0～1；将标签值 y_train 和 y_test的数据类型转换为 tf.int32。'''\n",
    "\n",
    "# 导入所需要的模块与包\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 导入Cifar-10数据集，将训练集和测试集存储在相应变量中\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 转换特征值的数据类型并进行标准化处理\n",
    "x_train, x_test = tf.cast(x_train, dtype=tf.float32) / 255.0, tf.cast(x_test, dtype=tf.float32) / 255.0\n",
    "\n",
    "# 转换标签值的数据类型\n",
    "y_train, y_test = tf.cast(y_train, dtype=tf.int32), tf.cast(y_test, dtype=tf.int32)\n",
    "\n",
    "# 显示数据集的特征值和标签值的 shape 属性值\n",
    "print(\"x_train.shape =\", x_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"x_test.shape =\", x_test.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543db84-99ce-4da7-9866-0a0ac1d585f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''步骤二，构建 CNN 模型，图像识别分类网络模型采用卷积神经网络，包括两\n",
    "个卷积层、两个池化层、4 个 Dropout 层、一个拉伸层、两个全连接层和一个输\n",
    "出层'''\n",
    "# 构建 CNN 模型\n",
    "model = tf.keras.models.Sequential([\n",
    "    \n",
    "    # 使用 Input 层明确指定输入形状\n",
    "    tf.keras.Input(shape=x_train.shape[1:]),  \n",
    "    \n",
    "    # 创建卷积层\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation=tf.nn.relu),\n",
    "    \n",
    "    # 创建最大池化层\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same'),  \n",
    "    \n",
    "    # 创建 Dropout 层\n",
    "    tf.keras.layers.Dropout(0.2),  \n",
    "    \n",
    "    # 创建第二个卷积层\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation=tf.nn.relu),\n",
    "    \n",
    "    # 创建最大池化层\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same'),  \n",
    "    \n",
    "    # 创建 Dropout 层\n",
    "    tf.keras.layers.Dropout(0.2),  \n",
    "    \n",
    "    # 创建拉伸层（Flatten）\n",
    "    tf.keras.layers.Flatten(),  \n",
    "    \n",
    "    # 创建全连接层\n",
    "    tf.keras.layers.Dense(512, activation='relu'),  \n",
    "    \n",
    "    # 创建 Dropout 层\n",
    "    tf.keras.layers.Dropout(0.2),  \n",
    "    \n",
    "    # 创建另一个全连接层\n",
    "    tf.keras.layers.Dense(256, activation='relu'),  \n",
    "    \n",
    "    # 创建 Dropout 层\n",
    "    tf.keras.layers.Dropout(0.5),  \n",
    "    \n",
    "    # 创建全连接层作为输出层\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "# 打印模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04b52a-4583-4359-a0d8-6a36cdccdaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''步骤三，编译、训练和评估 CNN 模型'''\n",
    "# 编译网络模型\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "# 训练网络模型\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=128, \n",
    "                    epochs=10, \n",
    "                    validation_split=0.2)\n",
    "\n",
    "# 评估网络模型\n",
    "model.evaluate(x_test, y_test, \n",
    "               batch_size=64, \n",
    "               verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3fd0b-3b07-4d8c-ae1a-827b3ffbbda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''步骤四，可视化训练的结果'''\n",
    "print(history.history)\n",
    "\n",
    "# 确保 epochs 数组的定义与 loss 和 acc 的数据一致\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# 创建画布并设置画面大小\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "# 在子图1中绘制损失函数的折线图\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, history.history['loss'], color='b', label='train')  # 蓝色线表示训练集损失\n",
    "plt.plot(epochs, history.history['val_loss'], color='r', label='validate')  # 红色线表示验证集损失\n",
    "plt.xlabel('Epochs')  # 添加横轴标签\n",
    "plt.ylabel('Loss')  # 添加纵轴标签\n",
    "plt.legend()  # 显示图例\n",
    "\n",
    "# 在子图2中绘制准确率的折线图\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, history.history['sparse_categorical_accuracy'], color='b', label='train')  # 蓝色线表示训练集准确率\n",
    "plt.plot(epochs, history.history['val_sparse_categorical_accuracy'], color='r', label='validate')  # 红色线表示验证集准确率\n",
    "plt.xlabel('Epochs')  # 添加横轴标签\n",
    "plt.ylabel('Accuracy')  # 添加纵轴标签\n",
    "plt.legend()  # 显示图例\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629da1b-7133-44cc-b4d2-0379fcbe9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''步骤五，应用卷积神经网络模型'''\n",
    "plt.figure()  # 创建画布\n",
    "\n",
    "for i in range(10):  # 循环显示10张图片\n",
    "    n = np.random.randint(1, 10000)  # 生成随机整数 n\n",
    "    plt.subplot(2, 5, i + 1)  # 创建子图 (2行5列)\n",
    "    plt.axis(\"off\")  # 不显示坐标轴\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置字体为 SimHei，支持中文显示\n",
    "\n",
    "    # 显示测试集中随机图片，使用灰度颜色映射\n",
    "    plt.imshow(x_test[n], cmap='gray')\n",
    "\n",
    "    # 将图片 reshape 为模型输入的形状 (1, 32, 32, 3)\n",
    "    demo = tf.reshape(x_test[n], (1, 32, 32, 3))\n",
    "\n",
    "    # 使用模型预测该图片的类别\n",
    "    y_pred = np.argmax(model.predict(demo))\n",
    "\n",
    "    # 设置子图标题，显示标签值与预测值\n",
    "    title = \"标签值: \" + str((y_test.numpy())[n, 0]) + \"\\n预测值: \" + str(y_pred)\n",
    "    plt.title(title)\n",
    "\n",
    "# 展示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ee02a-6ea4-49e2-b2ad-e677b98eb048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310(GPU)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
