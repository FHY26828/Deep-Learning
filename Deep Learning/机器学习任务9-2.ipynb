{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675ec987-3689-45e7-9a53-02a4836e3ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存图片: test_images/7_0.png\n",
      "保存图片: test_images/0_3.png\n",
      "保存图片: test_images/9_9.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 创建保存路径\n",
    "import os\n",
    "save_path = 'test_images'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 保存一些图片为 PNG\n",
    "def save_images(images, labels, indices):\n",
    "    for i in indices:\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "        file_name = f\"{save_path}/{label}_{i}.png\"\n",
    "        plt.imsave(file_name, img, cmap='gray')\n",
    "        print(f\"保存图片: {file_name}\")\n",
    "\n",
    "# 从测试集里保存 3 张图片 (你可以指定其他索引)\n",
    "save_images(x_test, y_test, [0, 3, 9])  # 保存索引 0, 1, 3 处的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a1eb1c-dc15-4970-9036-8f0675431665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图片形状: (60000, 28, 28, 1)\n",
      "训练集标签形状: (60000,)\n",
      "测试集图片形状: (10000, 28, 28, 1)\n",
      "测试集标签形状: (10000,)\n",
      "训练集单张图片通道数: 1\n",
      "测试集单张图片通道数: 1\n"
     ]
    }
   ],
   "source": [
    "# 步骤1：数据的读取与预处理\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "class DataSource:\n",
    "    def __init__(self):\n",
    "        # 尝试直接加载数据集\n",
    "        try:\n",
    "            (x_train, y_train), (x_test, y_test) = load_data()\n",
    "        except Exception as e:\n",
    "            print(\"加载数据集时出错:\", e)\n",
    "            return\n",
    "\n",
    "        # 增加一个通道维度\n",
    "        x_train = x_train[..., tf.newaxis]\n",
    "        x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "        # 像素值缩放到 [0, 1] 之间\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "        self.train_images, self.train_labels = x_train, y_train\n",
    "        self.test_images, self.test_labels = x_test, y_test\n",
    "\n",
    "# 创建 DataSource 实例，加载数据\n",
    "data = DataSource()\n",
    "\n",
    "# 打印训练集和测试集的形状\n",
    "print(f\"训练集图片形状: {data.train_images.shape}\")\n",
    "print(f\"训练集标签形状: {data.train_labels.shape}\")\n",
    "print(f\"测试集图片形状: {data.test_images.shape}\")\n",
    "print(f\"测试集标签形状: {data.test_labels.shape}\")\n",
    "\n",
    "# 验证是否为单通道\n",
    "print(f\"训练集单张图片通道数: {data.train_images.shape[-1]}\")\n",
    "print(f\"测试集单张图片通道数: {data.test_images.shape[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f846ccc2-84da-42bc-8126-ad7ee326e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤2：搭建卷积神经网络（CNN模型）\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # 打印模型结构\n",
    "        model.summary()\n",
    "        self.model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada16bf4-a569-461f-b2ca-3077b4fc964d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,322</span> (364.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,322\u001b[0m (364.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,322</span> (364.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,322\u001b[0m (364.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.3553\n",
      "Epoch 1: saving model to ./ckpt/cp-0001.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.3552 - val_accuracy: 0.9825 - val_loss: 0.0539\n",
      "Epoch 2/10\n",
      "\u001b[1m1874/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0492\n",
      "Epoch 2: saving model to ./ckpt/cp-0002.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0492 - val_accuracy: 0.9904 - val_loss: 0.0311\n",
      "Epoch 3/10\n",
      "\u001b[1m1870/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0315\n",
      "Epoch 3: saving model to ./ckpt/cp-0003.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0315 - val_accuracy: 0.9901 - val_loss: 0.0297\n",
      "Epoch 4/10\n",
      "\u001b[1m1872/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0253\n",
      "Epoch 4: saving model to ./ckpt/cp-0004.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0253 - val_accuracy: 0.9883 - val_loss: 0.0389\n",
      "Epoch 5/10\n",
      "\u001b[1m1865/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0181\n",
      "Epoch 5: saving model to ./ckpt/cp-0005.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0181 - val_accuracy: 0.9887 - val_loss: 0.0402\n",
      "Epoch 6/10\n",
      "\u001b[1m1865/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0151\n",
      "Epoch 6: saving model to ./ckpt/cp-0006.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0151 - val_accuracy: 0.9896 - val_loss: 0.0400\n",
      "Epoch 7/10\n",
      "\u001b[1m1870/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0121\n",
      "Epoch 7: saving model to ./ckpt/cp-0007.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0121 - val_accuracy: 0.9915 - val_loss: 0.0308\n",
      "Epoch 8/10\n",
      "\u001b[1m1868/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0104\n",
      "Epoch 8: saving model to ./ckpt/cp-0008.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.9903 - val_loss: 0.0351\n",
      "Epoch 9/10\n",
      "\u001b[1m1866/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0089\n",
      "Epoch 9: saving model to ./ckpt/cp-0009.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0089 - val_accuracy: 0.9910 - val_loss: 0.0356\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0075\n",
      "Epoch 10: saving model to ./ckpt/cp-0010.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9878 - val_loss: 0.0498\n",
      "模型已保存为 './keras/model.keras'\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0616\n",
      "准确率：98.78%，共测试了 10000 张图片\n",
      "平均误差： 0.03318753195926547\n"
     ]
    }
   ],
   "source": [
    "# 步骤3：训练模型、保存结果与可视化\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self):\n",
    "        self.network = CNN()  # 创建CNN实例\n",
    "        self.data = DataSource()  # 加载数据集\n",
    "\n",
    "    def train(self):\n",
    "        # 设置 TensorBoard 日志路径\n",
    "        logdir = \"./logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_cb = TensorBoard(log_dir=logdir)\n",
    "\n",
    "        # # 设置模型检查点路径\n",
    "        # check_path = './ckpt/cp-{epoch:04d}.ckpt'\n",
    "        # save_model_cb = ModelCheckpoint(check_path, save_weights_only=True, verbose=1)\n",
    "        # 设置模型检查点路径（每5个epoch保存一次）\n",
    "        check_path = './ckpt/cp-{epoch:04d}.weights.h5'\n",
    "\n",
    "        save_model_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=check_path,  # 修改文件后缀为 .weights.h5\n",
    "            save_weights_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "\n",
    "        # 编译模型\n",
    "        self.network.model.compile(optimizer='adam',\n",
    "                                   loss='sparse_categorical_crossentropy',\n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "        # 训练模型并保存日志\n",
    "        training_history = self.network.model.fit(\n",
    "            self.data.train_images,\n",
    "            self.data.train_labels,\n",
    "            epochs=10,\n",
    "            validation_data=(self.data.test_images, self.data.test_labels),\n",
    "            callbacks=[tensorboard_cb, save_model_cb]\n",
    "        )\n",
    "\n",
    "        # 保存模型为 .keras 格式\n",
    "        os.makedirs('./keras', exist_ok=True)\n",
    "        self.network.model.save('./keras/model.keras')\n",
    "        print(\"模型已保存为 './keras/model.keras'\")\n",
    "\n",
    "        # 打印最终测试结果\n",
    "        test_loss, test_acc = self.network.model.evaluate(self.data.test_images, \n",
    "                                                          self.data.test_labels)\n",
    "        print(f\"准确率：{test_acc * 100:.2f}%，共测试了 {len(self.data.test_labels)} 张图片\")\n",
    "        print(\"平均误差：\", np.average(training_history.history['loss']))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mnist_train = Train()\n",
    "    mnist_train.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65621fbc-8cfb-4e55-ad7e-931fce34a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "./test_images/7_0.png -> 预测数字为：7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "./test_images/0_3.png -> 预测数字为：0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "./test_images/9_9.png -> 预测数字为：9\n"
     ]
    }
   ],
   "source": [
    "# 步骤4：加载模型并进行预测\n",
    "from PIL import Image\n",
    "\n",
    "class Predict:\n",
    "    def __init__(self):\n",
    "        # 加载已训练的模型\n",
    "        self.model = tf.keras.models.load_model('./keras/model.keras')\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        # 读取并预处理图片\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        img = img.resize((28, 28))  # 确保图片大小为 28x28\n",
    "        img_array = np.array(img).reshape(1, 28, 28, 1) / 255.0  # 归一化\n",
    "\n",
    "        # 进行预测\n",
    "        prediction = self.model.predict(img_array)\n",
    "        predicted_label = np.argmax(prediction[0])\n",
    "        print(f\"{image_path} -> 预测数字为：{predicted_label}\")\n",
    "\n",
    "# 测试预测\n",
    "if __name__ == \"__main__\":\n",
    "    app = Predict()\n",
    "    app.predict('./test_images/7_0.png')\n",
    "    app.predict('./test_images/0_3.png')\n",
    "    app.predict('./test_images/9_9.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff76678-cc87-4155-8718-29bf9ba5409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\anaconda\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\anaconda\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in d:\\anaconda\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a080b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google in d:\\anaconda\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from google) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->google) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a788e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312(CPU)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
