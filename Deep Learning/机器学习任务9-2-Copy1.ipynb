{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb9f2d8-e6fc-4cc1-be40-c4c2c0767c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存图片: test_images/7_0.png\n",
      "保存图片: test_images/0_3.png\n",
      "保存图片: test_images/9_9.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 创建保存路径\n",
    "import os\n",
    "save_path = 'test_images'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 保存一些图片为 PNG\n",
    "def save_images(images, labels, indices):\n",
    "    for i in indices:\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "        file_name = f\"{save_path}/{label}_{i}.png\"\n",
    "        plt.imsave(file_name, img, cmap='gray')\n",
    "        print(f\"保存图片: {file_name}\")\n",
    "\n",
    "# 从测试集里保存 3 张图片 (你可以指定其他索引)\n",
    "save_images(x_test, y_test, [0, 3, 9])  # 保存索引 0, 1, 3 处的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fba4d5-af94-42f6-81da-7216522f76d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图片形状: (60000, 28, 28, 1)\n",
      "训练集标签形状: (60000,)\n",
      "测试集图片形状: (10000, 28, 28, 1)\n",
      "测试集标签形状: (10000,)\n",
      "训练集单张图片通道数: 1\n",
      "测试集单张图片通道数: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "class DataSource:\n",
    "    def __init__(self):\n",
    "        # 数据集路径配置（如果需要本地路径）\n",
    "#         data_path = os.path.abspath(os.path.dirname(__file__)) + '/data/mnist.npz'\n",
    "#         (x_train, y_train), (x_test, y_test) = load_data(path=data_path)\n",
    "\n",
    "        # 数据集路径配置（使用当前工作目录）\n",
    "        data_path = os.path.join(os.getcwd(), 'data', 'mnist.npz')\n",
    "\n",
    "        # 加载数据集（如果本地有文件则加载本地，否则从网上下载）\n",
    "        if os.path.exists(data_path):\n",
    "            (x_train, y_train), (x_test, y_test) = load_data(path=data_path)\n",
    "        else:\n",
    "            print(\"mnist.npz 文件不存在，从网上下载数据集...\")\n",
    "            (x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "        # 为数据增加一个通道维度\n",
    "        x_train = x_train[..., tf.newaxis]\n",
    "        x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "        # 将像素值缩放到 0 ~ 1 范围内\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "        # 将数据存储为类的属性\n",
    "        self.train_images, self.train_labels = x_train, y_train\n",
    "        self.test_images, self.test_labels = x_test, y_test\n",
    "\n",
    "# 创建 DataSource 实例，加载数据\n",
    "data = DataSource()\n",
    "\n",
    "# 打印训练集和测试集的形状\n",
    "print(f\"训练集图片形状: {data.train_images.shape}\")\n",
    "print(f\"训练集标签形状: {data.train_labels.shape}\")\n",
    "print(f\"测试集图片形状: {data.test_images.shape}\")\n",
    "print(f\"测试集标签形状: {data.test_labels.shape}\")\n",
    "\n",
    "# 验证是否为单通道\n",
    "print(f\"训练集单张图片通道数: {data.train_images.shape[-1]}\")\n",
    "print(f\"测试集单张图片通道数: {data.test_images.shape[-1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900bf3b7-be66-4d95-ba08-da8b0c7b3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤2：搭建卷积神经网络（CNN模型）\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self):\n",
    "        model = models.Sequential()\n",
    "        \n",
    "        # 第1层卷积层 + 最大池化层\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        # 第2层卷积层 + 最大池化层\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        # 第3层卷积层\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "        # 展平层 + 全连接层\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        \n",
    "        # 输出层（10类，使用softmax激活函数）\n",
    "        model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "        # 打印模型结构\n",
    "        model.summary()\n",
    "\n",
    "        self.model = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea5e5f3-f0be-46be-9f5e-2ef215f2ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤2：搭建卷积神经网络（CNN模型）\n",
    "class Train:\n",
    "    def __init__(self):\n",
    "        self.network = CNN()  # 创建CNN模型实例\n",
    "        self.data = DataSource()  # 加载数据集\n",
    "\n",
    "    def train(self):\n",
    "        # 设置模型检查点路径（每5个epoch保存一次）\n",
    "        check_path = './ckpt/cp-{epoch:04d}.ckpt'\n",
    "        save_model_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "            check_path, save_weights_only=True, verbose=1, save_freq='epoch'\n",
    "        )\n",
    "\n",
    "        # 编译模型\n",
    "        self.network.model.compile(optimizer='adam',\n",
    "                                   loss='sparse_categorical_crossentropy',\n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "        # 训练模型\n",
    "        self.network.model.fit(self.data.train_images, \n",
    "                               self.data.train_labels, \n",
    "                               epochs=10, \n",
    "                               callbacks=[save_model_cb])\n",
    "\n",
    "        # 测试模型\n",
    "        test_loss, test_acc = self.network.model.evaluate(self.data.test_images, \n",
    "                                                          self.data.test_labels)\n",
    "        print(f\"准确率：{test_acc * 100:.2f}%，共测试了 {len(self.data.test_labels)} 张图片\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e63437-7e13-45d9-82b3-c1eb35abfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤3：训练模型与保存结果\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self):\n",
    "        model = models.Sequential()\n",
    "        \n",
    "        # 第1层卷积层 + 最大池化层\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        # 第2层卷积层 + 最大池化层\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        # 第3层卷积层\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "        # 展平层 + 全连接层\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        \n",
    "        # 输出层（10类，使用softmax激活函数）\n",
    "        model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "        # 打印模型结构\n",
    "        model.summary()\n",
    "\n",
    "        self.model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6748e71-3a88-477f-ac45-7df3b178c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 16s 6ms/step - loss: 0.1458 - accuracy: 0.9544 - val_loss: 0.0491 - val_accuracy: 0.9836\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0452 - accuracy: 0.9860 - val_loss: 0.0391 - val_accuracy: 0.9878\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.0354 - val_accuracy: 0.9887\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0362 - val_accuracy: 0.9882\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0273 - val_accuracy: 0.9915\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0333 - val_accuracy: 0.9915\n",
      "Epoch 7/10\n",
      "1452/1875 [======================>.......] - ETA: 2s - loss: 0.0128 - accuracy: 0.9958"
     ]
    }
   ],
   "source": [
    "\n",
    "# 步骤4：可视化训练过程（TensorBoard）\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "class Train:\n",
    "    def __init__(self):\n",
    "        self.network = CNN()  # 创建CNN实例\n",
    "        self.data = DataSource()  # 加载数据集\n",
    "\n",
    "    def train(self):\n",
    "        # 配置TensorBoard日志路径\n",
    "        logdir = \"./logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_cb = TensorBoard(log_dir=logdir)\n",
    "\n",
    "        # 编译模型\n",
    "        self.network.model.compile(optimizer='adam',\n",
    "                                   loss='sparse_categorical_crossentropy',\n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "        # 训练模型并进行可视化监控\n",
    "        training_history = self.network.model.fit(self.data.train_images,\n",
    "                                                  self.data.train_labels,\n",
    "                                                  epochs=10,\n",
    "                                                  validation_data=(self.data.test_images,\n",
    "                                                                   self.data.test_labels),\n",
    "                                                  callbacks=[tensorboard_cb])\n",
    "\n",
    "        # 打印最终测试结果\n",
    "        test_loss, test_acc = self.network.model.evaluate(self.data.test_images, \n",
    "                                                          self.data.test_labels)\n",
    "        print(f\"准确率：{test_acc * 100:.2f}%，共测试了 {len(self.data.test_labels)} 张图片\")\n",
    "        print(\"平均误差：\", np.average(training_history.history['loss']))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mnist_train = Train()\n",
    "    mnist_train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458011a6-f477-429e-8826-ce5de3ba1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤5：预测新图片\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "class Predict:\n",
    "    def __init__(self):\n",
    "        self.network = CNN()  # 创建CNN实例\n",
    "        # 加载训练好的模型权重\n",
    "        #self.network.model.load_weights('./ckpt/cp-0004.ckpt')\n",
    "        # 在训练结束后保存模型为 .h5 文件\n",
    "        self.model = tf.keras.models.load_model('./ckpt/model.h5')\n",
    "\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        # 读取并处理图片\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        flatten_img = np.reshape(img, (28, 28, 1))\n",
    "        x = np.array([1 - flatten_img])\n",
    "\n",
    "        # 进行预测\n",
    "        y = self.network.model.predict(x)\n",
    "        print(f\"{image_path} -> 预测数字为：{np.argmax(y[0])}\")\n",
    "\n",
    "# 测试预测\n",
    "if __name__ == \"__main__\":\n",
    "    app = Predict()\n",
    "    app.predict('./test_images/7_0.png')\n",
    "    app.predict('./test_images/9_9.png')\n",
    "    app.predict('./test_images/0_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e12006-f36a-4b3b-b2f9-9a01de3a33bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970c11f-df12-4837-8985-1c0582559fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (GPU)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
